{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2a27aacc-7f7a-465f-999d-a2ed04696f9a",
   "metadata": {},
   "source": [
    "## Batch 2 - Coding Solution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f131b0c4-a4ec-4055-b8de-fa386fcd806e",
   "metadata": {},
   "source": [
    "# 1. Object Detection with YOLOv5 (Using Pretrained Weights)\n",
    "# Problem: Detect objects using pre-trained YOLOv5 model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d462d564-b9f2-4594-9472-969ef02ecf15",
   "metadata": {},
   "source": [
    "# !pip install ultralytics\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# Load model\n",
    "model = YOLO('yolov5s.pt')  # Small YOLOv5 model\n",
    "\n",
    "# Inference\n",
    "results = model('sample.jpg')  # Image path\n",
    "\n",
    "# Show predictions\n",
    "results.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71fc11cf-c336-4771-9399-9a5b64cecbb5",
   "metadata": {},
   "source": [
    "# 2.Preprocessing Image for ResNet Input\n",
    "# Problem: Write a function to preprocess image for pretrained ResNet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12b97fd4-c782-4ff7-9dad-2fb670da67ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "\n",
    "def preprocess_image(img_path):\n",
    "    image = Image.open(img_path).convert(\"RGB\")\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                             [0.229, 0.224, 0.225])\n",
    "    ])\n",
    "    return transform(image).unsqueeze(0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48ceb879-fd03-4d99-9ec6-4ecf01eda8de",
   "metadata": {},
   "source": [
    "# 3. CNN for CIFAR-10 Classification\n",
    "# Problem: Build a CNN model to classify CIFAR-10 images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fd5dbbc-e01b-483f-aed8-c0b406f878fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.layers import Dropout\n",
    "\n",
    "model = Sequential([\n",
    "    Conv2D(32, (3,3), activation='relu', input_shape=(32,32,3)),\n",
    "    MaxPooling2D(2,2),\n",
    "    Conv2D(64, (3,3), activation='relu'),\n",
    "    MaxPooling2D(2,2),\n",
    "    Flatten(),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(0.3),\n",
    "    Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.fit(x_train, y_train, epochs=10, validation_data=(x_test, y_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd3f5d08-7399-408e-aab0-79a8f7174088",
   "metadata": {},
   "source": [
    "# 4. Scenario: Face Mask Detection â€“ Real-Time Webcam Classifier\n",
    "# Problem: Build a real-time face mask detector using a trained CNN model and OpenCV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e679ce78-eddc-4fe5-ab03-62d9f7f1623b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from tensorflow.keras.models import load_model\n",
    "import numpy as np\n",
    "\n",
    "model = load_model(\"mask_detector.h5\")\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "while True:\n",
    "    _, frame = cap.read()\n",
    "    face = cv2.resize(frame, (128, 128)) / 255.0\n",
    "    prediction = model.predict(np.expand_dims(face, axis=0))[0][0]\n",
    "    label = \"Mask\" if prediction < 0.5 else \"No Mask\"\n",
    "\n",
    "    cv2.putText(frame, label, (10, 40), cv2.FONT_HERSHEY_SIMPLEX, 1, (255,255,255), 2)\n",
    "    cv2.imshow(\"Face Mask Detection\", frame)\n",
    "    if cv2.waitKey(1) == ord('q'):\n",
    "        break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f1e57f6-97da-4c9a-be25-74a48d1e08a5",
   "metadata": {},
   "source": [
    "# 5. Scenario: Custom Transfer Learning with Frozen + Trainable Layers\n",
    "# Problem: Load a pretrained MobileNetV2 model, freeze base layers, add custom classifier, and fine-tune the top few layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cef02bb2-dc3f-45d5-ab6d-98e2df278ba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "base_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=(224,224,3))\n",
    "for layer in base_model.layers[:-20]:\n",
    "    layer.trainable = False\n",
    "\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(128, activation='relu')(x)\n",
    "output = Dense(2, activation='softmax')(x)\n",
    "\n",
    "model = Model(inputs=base_model.input, outputs=output)\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36e47406-50de-41a3-bca3-ab66998f8758",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
