{"cells":[{"cell_type":"markdown","id":"91124f4b-2e45-4a46-98de-52c3f6f3f5a9","metadata":{"id":"91124f4b-2e45-4a46-98de-52c3f6f3f5a9"},"source":["## **1.Module Not Found Error**"]},{"cell_type":"code","execution_count":null,"id":"dd3b401c-cedb-469d-b79d-8c3acd4011f8","metadata":{"id":"dd3b401c-cedb-469d-b79d-8c3acd4011f8","outputId":"3d15f2fe-9fca-4f96-a078-8b234742af97"},"outputs":[{"ename":"ModuleNotFoundError","evalue":"No module named 'tensorflow.keras.layer'","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)","Cell \u001b[1;32mIn[1], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Missing import for TensorFlow\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Sequential\n\u001b[1;32m----> 5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlayer\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Dense\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# Generate dummy data\u001b[39;00m\n\u001b[0;32m      8\u001b[0m X_train \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mrand(\u001b[38;5;241m100\u001b[39m, \u001b[38;5;241m10\u001b[39m)\n","\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow.keras.layer'"]}],"source":["import numpy as np\n","\n","# Missing import for TensorFlow\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layer import Dense\n","\n","# Generate dummy data\n","X_train = np.random.rand(100, 10)\n","Y_train = np.random.randint(0, 2, size=(100,))\n","\n","# Define the model\n","model = Sequential([\n","    Dense(32, activation='relu', input_shape=(10,)),\n","    Dense(1, activation='sigmoid')\n","])\n","\n","# Compile model\n","model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n","\n","# Train model\n","model.fit(X_train, y_train, epochs=5)\n"]},{"cell_type":"markdown","id":"89438662-8a79-44be-a241-3b47ee4f2b5f","metadata":{"id":"89438662-8a79-44be-a241-3b47ee4f2b5f"},"source":["## **1.Solution**"]},{"cell_type":"code","execution_count":null,"id":"3591db08-35d1-4b2e-947b-409572adabe7","metadata":{"id":"3591db08-35d1-4b2e-947b-409572adabe7","outputId":"5a8aea54-af44-4ddd-965a-4728dfa18f5a"},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/5\n","4/4 [==============================] - 4s 16ms/step - loss: 0.7250 - accuracy: 0.4900\n","Epoch 2/5\n","4/4 [==============================] - 0s 34ms/step - loss: 0.7152 - accuracy: 0.5000\n","Epoch 3/5\n","4/4 [==============================] - 0s 16ms/step - loss: 0.7094 - accuracy: 0.5000\n","Epoch 4/5\n","4/4 [==============================] - 0s 28ms/step - loss: 0.7046 - accuracy: 0.5000\n","Epoch 5/5\n","4/4 [==============================] - 0s 27ms/step - loss: 0.7020 - accuracy: 0.5100\n"]},{"data":{"text/plain":["<keras.callbacks.History at 0x2658ca19050>"]},"execution_count":2,"metadata":{},"output_type":"execute_result"}],"source":["import numpy as np\n","import tensorflow as tf  # Added missing import\n","\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Dense\n","\n","# Generate dummy data\n","X_train = np.random.rand(100, 10)\n","y_train = np.random.randint(0, 2, size=(100,))\n","\n","# Define the model\n","model = Sequential([\n","    Dense(32, activation='relu', input_shape=(10,)),\n","    Dense(1, activation='sigmoid')\n","])\n","\n","# Compile model\n","model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n","\n","# Train model\n","model.fit(X_train, y_train, epochs=5)\n"]},{"cell_type":"markdown","id":"c4e65f8e-6135-4d12-aa11-e1f48a29dc69","metadata":{"id":"c4e65f8e-6135-4d12-aa11-e1f48a29dc69"},"source":["## **2.Mismatched Input Shape in CNN**"]},{"cell_type":"code","execution_count":null,"id":"019a3404-e926-4bf1-81dd-92f0052c3078","metadata":{"id":"019a3404-e926-4bf1-81dd-92f0052c3078","outputId":"d5ad740a-6699-4034-d2af-34bfcaf6f30b"},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/5\n"]},{"ename":"ValueError","evalue":"in user code:\n\n    File \"C:\\Users\\Admin\\anaconda3\\envs\\deepL\\Lib\\site-packages\\keras\\engine\\training.py\", line 1284, in train_function  *\n        return step_function(self, iterator)\n    File \"C:\\Users\\Admin\\anaconda3\\envs\\deepL\\Lib\\site-packages\\keras\\engine\\training.py\", line 1268, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Users\\Admin\\anaconda3\\envs\\deepL\\Lib\\site-packages\\keras\\engine\\training.py\", line 1249, in run_step  **\n        outputs = model.train_step(data)\n    File \"C:\\Users\\Admin\\anaconda3\\envs\\deepL\\Lib\\site-packages\\keras\\engine\\training.py\", line 1050, in train_step\n        y_pred = self(x, training=True)\n    File \"C:\\Users\\Admin\\anaconda3\\envs\\deepL\\Lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"C:\\Users\\Admin\\anaconda3\\envs\\deepL\\Lib\\site-packages\\keras\\engine\\input_spec.py\", line 253, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Exception encountered when calling layer 'sequential_1' (type Sequential).\n    \n    Input 0 of layer \"conv2d\" is incompatible with the layer: expected min_ndim=4, found ndim=3. Full shape received: (None, 32, 32)\n    \n    Call arguments received by layer 'sequential_1' (type Sequential):\n      • inputs=tf.Tensor(shape=(None, 32, 32), dtype=float32)\n      • training=True\n      • mask=None\n","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)","Cell \u001b[1;32mIn[3], line 19\u001b[0m\n\u001b[0;32m     11\u001b[0m model \u001b[38;5;241m=\u001b[39m Sequential([\n\u001b[0;32m     12\u001b[0m     Conv2D(\u001b[38;5;241m32\u001b[39m, (\u001b[38;5;241m3\u001b[39m,\u001b[38;5;241m3\u001b[39m), activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrelu\u001b[39m\u001b[38;5;124m'\u001b[39m, input_shape\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m32\u001b[39m,\u001b[38;5;241m32\u001b[39m,\u001b[38;5;241m3\u001b[39m)),\n\u001b[0;32m     13\u001b[0m     Flatten(),\n\u001b[0;32m     14\u001b[0m     Dense(\u001b[38;5;241m10\u001b[39m, activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msoftmax\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     15\u001b[0m ])\n\u001b[0;32m     17\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(optimizer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124madam\u001b[39m\u001b[38;5;124m'\u001b[39m, loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msparse_categorical_crossentropy\u001b[39m\u001b[38;5;124m'\u001b[39m, metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m---> 19\u001b[0m model\u001b[38;5;241m.\u001b[39mfit(X_train, y_train, epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m)\n","File \u001b[1;32m~\\anaconda3\\envs\\deepL\\Lib\\site-packages\\keras\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n","File \u001b[1;32m~\\AppData\\Local\\Temp\\__autograph_generated_filegsjgytmm.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__train_function\u001b[1;34m(iterator)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     14\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m     retval_ \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(step_function), (ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m), ag__\u001b[38;5;241m.\u001b[39mld(iterator)), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[0;32m     17\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n","\u001b[1;31mValueError\u001b[0m: in user code:\n\n    File \"C:\\Users\\Admin\\anaconda3\\envs\\deepL\\Lib\\site-packages\\keras\\engine\\training.py\", line 1284, in train_function  *\n        return step_function(self, iterator)\n    File \"C:\\Users\\Admin\\anaconda3\\envs\\deepL\\Lib\\site-packages\\keras\\engine\\training.py\", line 1268, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Users\\Admin\\anaconda3\\envs\\deepL\\Lib\\site-packages\\keras\\engine\\training.py\", line 1249, in run_step  **\n        outputs = model.train_step(data)\n    File \"C:\\Users\\Admin\\anaconda3\\envs\\deepL\\Lib\\site-packages\\keras\\engine\\training.py\", line 1050, in train_step\n        y_pred = self(x, training=True)\n    File \"C:\\Users\\Admin\\anaconda3\\envs\\deepL\\Lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"C:\\Users\\Admin\\anaconda3\\envs\\deepL\\Lib\\site-packages\\keras\\engine\\input_spec.py\", line 253, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Exception encountered when calling layer 'sequential_1' (type Sequential).\n    \n    Input 0 of layer \"conv2d\" is incompatible with the layer: expected min_ndim=4, found ndim=3. Full shape received: (None, 32, 32)\n    \n    Call arguments received by layer 'sequential_1' (type Sequential):\n      • inputs=tf.Tensor(shape=(None, 32, 32), dtype=float32)\n      • training=True\n      • mask=None\n"]}],"source":["import numpy as np\n","import tensorflow as tf\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Conv2D, Flatten, Dense\n","\n","# Generate dummy image data\n","X_train = np.random.rand(100, 32, 32)  # Error: Missing the channel dimension\n","y_train = np.random.randint(0, 10, size=(100,))\n","\n","# Define CNN Model\n","model = Sequential([\n","    Conv2D(32, (3,3), activation='relu', input_shape=(32,32,3)),\n","    Flatten(),\n","    Dense(10, activation='softmax')\n","])\n","\n","model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n","\n","model.fit(X_train, y_train, epochs=5)\n"]},{"cell_type":"markdown","id":"8ce51ed3-f5c7-4300-be53-cc40c7700b3e","metadata":{"id":"8ce51ed3-f5c7-4300-be53-cc40c7700b3e"},"source":["## **2.Solution**"]},{"cell_type":"code","execution_count":null,"id":"4c00bf3b-6979-4282-b559-013ceef1e3c8","metadata":{"id":"4c00bf3b-6979-4282-b559-013ceef1e3c8","outputId":"c93b4361-586c-44ee-9904-dbd94bb732d2"},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/5\n","4/4 [==============================] - 3s 74ms/step - loss: 2.5478 - accuracy: 0.1100\n","Epoch 2/5\n","4/4 [==============================] - 0s 75ms/step - loss: 1.8274 - accuracy: 0.5500\n","Epoch 3/5\n","4/4 [==============================] - 0s 65ms/step - loss: 1.3347 - accuracy: 0.8600\n","Epoch 4/5\n","4/4 [==============================] - 0s 65ms/step - loss: 0.7543 - accuracy: 0.9900\n","Epoch 5/5\n","4/4 [==============================] - 0s 54ms/step - loss: 0.4321 - accuracy: 1.0000\n"]},{"data":{"text/plain":["<keras.callbacks.History at 0x2658de36650>"]},"execution_count":4,"metadata":{},"output_type":"execute_result"}],"source":["import numpy as np\n","import tensorflow as tf\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Conv2D, Flatten, Dense\n","\n","# Generate dummy image data\n","X_train = np.random.rand(100, 32, 32, 3)  # Added channel dimension (RGB)\n","y_train = np.random.randint(0, 10, size=(100,))\n","\n","# Define CNN Model\n","model = Sequential([\n","    Conv2D(32, (3,3), activation='relu', input_shape=(32,32,3)),\n","    Flatten(),\n","    Dense(10, activation='softmax')\n","])\n","\n","model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n","\n","model.fit(X_train, y_train, epochs=5)\n"]},{"cell_type":"markdown","id":"15215ade-6c2c-4159-b400-42a8537267bf","metadata":{"id":"15215ade-6c2c-4159-b400-42a8537267bf"},"source":["## **3.Undefined Variable Error**"]},{"cell_type":"code","execution_count":null,"id":"b7fc93d2-4027-4a84-ae6e-c60622d7fb38","metadata":{"id":"b7fc93d2-4027-4a84-ae6e-c60622d7fb38","outputId":"00703b74-8081-48d1-cafa-465c6e41931d"},"outputs":[{"name":"stdout","output_type":"stream","text":["WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n"]},{"ename":"NameError","evalue":"name 'INIT_LR' is not defined","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[1;32mIn[5], line 18\u001b[0m\n\u001b[0;32m     16\u001b[0m model \u001b[38;5;241m=\u001b[39m Model(inputs\u001b[38;5;241m=\u001b[39mbaseModel\u001b[38;5;241m.\u001b[39minput, outputs\u001b[38;5;241m=\u001b[39mheadModel)\n\u001b[0;32m     17\u001b[0m \u001b[38;5;66;03m# Define missing variables\u001b[39;00m\n\u001b[1;32m---> 18\u001b[0m opt \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39moptimizers\u001b[38;5;241m.\u001b[39mAdam(learning_rate\u001b[38;5;241m=\u001b[39mINIT_LR) \n\u001b[0;32m     19\u001b[0m lr_schedule \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39moptimizers\u001b[38;5;241m.\u001b[39mschedules\u001b[38;5;241m.\u001b[39mExponentialDecay(\n\u001b[0;32m     20\u001b[0m     initial_learning_rate\u001b[38;5;241m=\u001b[39mINIT_LR,\n\u001b[0;32m     21\u001b[0m     decay_steps\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1000\u001b[39m,  \u001b[38;5;66;03m# Adjust this based on dataset size\u001b[39;00m\n\u001b[0;32m     22\u001b[0m     decay_rate\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.96\u001b[39m,  \u001b[38;5;66;03m# Reduce LR by 4% every 1000 steps\u001b[39;00m\n\u001b[0;32m     23\u001b[0m     staircase\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m     24\u001b[0m )\n\u001b[0;32m     26\u001b[0m \u001b[38;5;66;03m# Compile model\u001b[39;00m\n","\u001b[1;31mNameError\u001b[0m: name 'INIT_LR' is not defined"]}],"source":["import numpy as np\n","import tensorflow as tf\n","from tensorflow.keras.applications import MobileNetV2\n","from tensorflow.keras.layers import AveragePooling2D, Flatten, Dense, Input\n","from tensorflow.keras.optimizers import Adam\n","from tensorflow.keras.models import Model\n","\n","# Load pre-trained MobileNetV2 model\n","baseModel = MobileNetV2(weights=\"imagenet\", include_top=False, input_tensor=Input(shape=(224, 224, 3)))\n","\n","# Add custom layers\n","headModel = baseModel.output\n","headModel = Flatten(name=\"flatten\")(headModel)\n","headModel = Dense(128, activation=\"relu\")(headModel)\n","headModel = Dense(1, activation=\"sigmoid\")(headModel)\n","model = Model(inputs=baseModel.input, outputs=headModel)\n","# Define missing variables\n","opt = tf.keras.optimizers.Adam(learning_rate=INIT_LR)\n","lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n","    initial_learning_rate=INIT_LR,\n","    decay_steps=1000,  # Adjust this based on dataset size\n","    decay_rate=0.96,  # Reduce LR by 4% every 1000 steps\n","    staircase=True\n",")\n","\n","# Compile model\n","opt = Adam(learning_rate=INIT_LR)  # Error: Undefined variables\n","model.compile(loss=\"binary_crossentropy\", optimizer=opt, metrics=[\"accuracy\"])\n","print(\"Model compiled successfully\")\n"]},{"cell_type":"markdown","id":"e80b72ae-a80b-4284-bf19-a40b3a3c9f44","metadata":{"id":"e80b72ae-a80b-4284-bf19-a40b3a3c9f44"},"source":["## **3. Solution**"]},{"cell_type":"code","execution_count":null,"id":"345249e5-3704-4743-a95e-a47596a5a29f","metadata":{"id":"345249e5-3704-4743-a95e-a47596a5a29f","outputId":"673dd248-8450-47e2-ff18-9ead58ea7742"},"outputs":[{"name":"stdout","output_type":"stream","text":["WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n","Model compiled successfully\n"]}],"source":["import numpy as np\n","import tensorflow as tf\n","from tensorflow.keras.applications import MobileNetV2\n","from tensorflow.keras.layers import AveragePooling2D, Flatten, Dense, Input\n","from tensorflow.keras.optimizers import Adam\n","from tensorflow.keras.models import Model\n","\n","# Load pre-trained MobileNetV2 model\n","baseModel = MobileNetV2(weights=\"imagenet\", include_top=False, input_tensor=Input(shape=(224, 224, 3)))\n","\n","# Add custom layers\n","headModel = baseModel.output\n","headModel = Flatten(name=\"flatten\")(headModel)\n","headModel = Dense(128, activation=\"relu\")(headModel)\n","headModel = Dense(1, activation=\"sigmoid\")(headModel)\n","model = Model(inputs=baseModel.input, outputs=headModel)\n","# Define missing variables\n","INIT_LR = 0.0001\n","EPOCHS = 20\n","opt = tf.keras.optimizers.Adam(learning_rate=INIT_LR)\n","# Alternative: Use Learning Rate Scheduler if decay is needed\n","lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n","    initial_learning_rate=INIT_LR,\n","    decay_steps=1000,  # Adjust this based on dataset size\n","    decay_rate=0.96,  # Reduce LR by 4% every 1000 steps\n","    staircase=True\n",")\n","\n","# Compile model\n","opt = Adam(learning_rate=INIT_LR)  # Error: Undefined variables\n","model.compile(loss=\"binary_crossentropy\", optimizer=opt, metrics=[\"accuracy\"])\n","print(\"Model compiled successfully\")"]},{"cell_type":"markdown","id":"2c938fb3-b5a9-497a-8fb4-b8f8d7128a61","metadata":{"id":"2c938fb3-b5a9-497a-8fb4-b8f8d7128a61"},"source":[" **4.FileNotFoundError                         "]},{"cell_type":"code","execution_count":null,"id":"49b425f7-cdf1-4951-9b20-27396d547a2a","metadata":{"id":"49b425f7-cdf1-4951-9b20-27396d547a2a","outputId":"7ba97622-04f6-4a77-890c-ffbbf900fcc6"},"outputs":[{"ename":"FileNotFoundError","evalue":"[Errno 2] No such file or directory: 'D:\\\\Hope AI\\\\Quiz Community\\\\Deep Learning\\\\flow.jpg'","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","Cell \u001b[1;32mIn[16], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# ❌ ERROR: Wrong file name or missing file\u001b[39;00m\n\u001b[0;32m      4\u001b[0m image_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mflow.jpg\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m----> 5\u001b[0m img \u001b[38;5;241m=\u001b[39m Image\u001b[38;5;241m.\u001b[39mopen(image_path)  \u001b[38;5;66;03m# This will raise a FileNotFoundError\u001b[39;00m\n\u001b[0;32m      7\u001b[0m img\u001b[38;5;241m.\u001b[39mshow()\n","File \u001b[1;32m~\\anaconda3\\envs\\deepL\\Lib\\site-packages\\PIL\\Image.py:3277\u001b[0m, in \u001b[0;36mopen\u001b[1;34m(fp, mode, formats)\u001b[0m\n\u001b[0;32m   3274\u001b[0m     filename \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mrealpath(os\u001b[38;5;241m.\u001b[39mfspath(fp))\n\u001b[0;32m   3276\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m filename:\n\u001b[1;32m-> 3277\u001b[0m     fp \u001b[38;5;241m=\u001b[39m builtins\u001b[38;5;241m.\u001b[39mopen(filename, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   3278\u001b[0m     exclusive_fp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m   3280\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n","\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'D:\\\\Hope AI\\\\Quiz Community\\\\Deep Learning\\\\flow.jpg'"]}],"source":["from PIL import Image\n","\n","# ❌ ERROR: Wrong file name or missing file\n","image_path = \"flow.jpg\"\n","img = Image.open(image_path)  # This will raise a FileNotFoundError\n","\n","img.show()\n"]},{"cell_type":"code","execution_count":null,"id":"a5c7b872-6252-47e3-ad88-edc650b44c26","metadata":{"id":"a5c7b872-6252-47e3-ad88-edc650b44c26","outputId":"06c2af11-199d-47d8-cbcc-b5b955d7148b"},"outputs":[{"name":"stdout","output_type":"stream","text":["Preprocessed image shape: (1, 224, 224, 3)\n"]}],"source":["import tensorflow as tf\n","from tensorflow.keras.applications.mobilenet_v2 import preprocess_input\n","from tensorflow.keras.preprocessing import image\n","import numpy as np\n","from PIL import Image\n","\n","# ✅ Corrected file path (Make sure the file exists)\n","image_path = \"flower.jpg\"  # Provide the correct path\n","\n","# ✅ Open the image properly using PIL\n","img = Image.open(image_path)\n","\n","# ✅ Correctly resize the image (Use tuple)\n","img = img.resize((224, 224))\n","\n","# ✅ Convert image to array before expanding dimensions\n","img_array = image.img_to_array(img)\n","\n","# ✅ Expand dimensions correctly for model input\n","img_array = np.expand_dims(img_array, axis=0)\n","\n","# ✅ Preprocess image for MobileNetV2\n","img_array = preprocess_input(img_array)\n","\n","print(\"Preprocessed image shape:\", img_array.shape)  # Expected Output: (1, 224, 224, 3)\n"]},{"cell_type":"code","execution_count":null,"id":"9d0e9680-0566-433a-9c97-365eaa1fb575","metadata":{"id":"9d0e9680-0566-433a-9c97-365eaa1fb575"},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.0"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":5}