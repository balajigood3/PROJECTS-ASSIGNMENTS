{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d9b95c75-8f25-4913-b9fa-0b4fc93d9e20",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ollama\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "683f234f-6da7-4b9d-b52e-fca3ddcba748",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_completion(prompt, model=\"llama3\"):\n",
    "    response = ollama.chat(model=model, messages=[{\"role\": \"user\", \"content\": prompt}])\n",
    "    return response['message']['content']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7191ac4d-b460-442b-8e7f-7e39d729605d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The capital of France is Paris.\n"
     ]
    }
   ],
   "source": [
    "response = get_completion(\"What is the capital of France?\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "09fa4a03-ebd2-42f5-9cf9-25398603cbdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The letters in \"lollipop\" are:\n",
      "\n",
      "L-O-L-L-I-P-O-P\n",
      "\n",
      "Reversing them gives:\n",
      "\n",
      "P-O-P-I-L-L-O-L\n"
     ]
    }
   ],
   "source": [
    "response = get_completion(\"Take the letters in lollipop and reverse them\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7e3e7b2f-d6eb-4d5b-a62b-fa0631dfa35c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The reversed letters are:\n",
      "\n",
      "p-o-p-i-l-o-l\n"
     ]
    }
   ],
   "source": [
    "response = get_completion(\"Take the letters in l-o-l-l-i-p-o-p and reverse them\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "542395ba-6c00-4927-857b-18ec4208c05a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_completion_from_messages(messages, model=\"llama3\"):\n",
    "    response = ollama.chat(model=model, messages=messages)\n",
    "    return response['message']['content']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2899998e-e3a0-4b77-9f85-0837c6b7e705",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In the garden, oh so bright,\n",
      "Grew a carrot with joy in sight.\n",
      "It danced and twirled with glee,\n",
      "A happy veggie, as happy as can be!\n",
      "Its orange hue was full of cheer,\n",
      "This carrot's happiness was crystal clear!\n"
     ]
    }
   ],
   "source": [
    "messages = [\n",
    "    {'role': 'system', 'content': \"You are an assistant who responds in the style of Dr Seuss.\"},\n",
    "    {'role': 'user', 'content': \"Write me a very short poem about a happy carrot\"}\n",
    "]\n",
    "\n",
    "response = get_completion_from_messages(messages)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ff11ee5f-92ea-4277-8ae8-a9d8b8da9099",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In the sunny vegetable patch, a bright orange carrot named Carl basked in the warm rays, his leafy greens swaying gently in the breeze as he dreamed of being the star of the salad bar at the nearby farm-to-table restaurant.\n"
     ]
    }
   ],
   "source": [
    "# Length restriction example\n",
    "messages = [\n",
    "    {'role': 'system', 'content': 'All your responses must be one sentence long.'},\n",
    "    {'role': 'user', 'content': 'Write me a story about a happy carrot'},\n",
    "]\n",
    "response = get_completion_from_messages(messages)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5b266cca-1525-4ec6-a05b-81876e5f52a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In the bright green garden, where sunshine poured like rain, grew a carrot so cheerful, it sparkled with joy and couldn't complain!\n"
     ]
    }
   ],
   "source": [
    "# Combined example\n",
    "messages = [\n",
    "    {'role': 'system', 'content': \"\"\"You are an assistant who responds in the style of Dr Seuss.\n",
    "    All your responses must be one sentence long.\"\"\"},\n",
    "    {'role': 'user', 'content': \"Write me a story about a happy carrot\"}\n",
    "]\n",
    "response = get_completion_from_messages(messages)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0be7fa8e-e682-4e03-bc68-c9ccad024c5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_completion_and_token_count(messages, model=\"llama3\"):\n",
    "    response = ollama.chat(model=model, messages=messages)\n",
    "    \n",
    "    # Ollama does not return exact token counts, so we estimate\n",
    "    formatted_prompt = \"\\n\".join([msg[\"content\"] for msg in messages])\n",
    "    \n",
    "    token_dict = {\n",
    "        'prompt_tokens': len(formatted_prompt.split()),  # Approximate count\n",
    "        'completion_tokens': len(response['message']['content'].split()),\n",
    "        'total_tokens': len(formatted_prompt.split()) + len(response['message']['content'].split()),\n",
    "    }\n",
    "\n",
    "    return response['message']['content'], token_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "72559a7e-3e0c-41d0-bf51-629e94e3dab9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response: What a delightful task, I must say!\n",
      "Here's a little ditty for you, come what may:\n",
      "\n",
      "In the garden, oh so bright,\n",
      "Grew a carrot with a heart full of light.\n",
      "He danced and sang with glee,\n",
      "A happy carrot, as happy as can be!\n",
      "\n",
      "The end.\n",
      "Token Usage: {'prompt_tokens': 22, 'completion_tokens': 47, 'total_tokens': 69}\n"
     ]
    }
   ],
   "source": [
    "messages = [\n",
    "    {'role': 'system', 'content': \"You are an assistant who responds in the style of Dr Seuss.\"},\n",
    "    {'role': 'user', 'content': \"Write me a very short poem about a happy carrot\"}\n",
    "]\n",
    "\n",
    "response, token_dict = get_completion_and_token_count(messages)\n",
    "\n",
    "print(\"Response:\", response)\n",
    "print(\"Token Usage:\", token_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93dde44e-9c60-4c5d-a885-04f20ef4b6ca",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AgenticAI",
   "language": "python",
   "name": "agenticai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
